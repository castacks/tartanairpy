

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TartanGround Dataset &mdash; TartanAir  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=5929fcd5"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API Reference" href="usage.html" />
    <link rel="prev" title="Dense Correspondence / Flow Sampling" href="flow_sampling.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            TartanAir
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">TartanGround Dataset</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#quick-links">Quick Links</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dataset-structure">Dataset Structure</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#directory-layout">Directory Layout</a></li>
<li class="toctree-l3"><a class="reference internal" href="#robot-platforms">Robot Platforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="#camera-configuration">Camera Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#available-camera-names">Available Camera Names</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sensor-modalities">Sensor Modalities</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#available-modalities">Available Modalities</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#download-dataset">Download Dataset</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#download-examples">Download Examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="#multi-threaded-download">Multi-threaded Download</a></li>
<li class="toctree-l3"><a class="reference internal" href="#download-process-notes">Download Process Notes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dataset-statistics">Dataset Statistics</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#environment-categories">Environment Categories</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#semantic-occupancy-maps">Semantic Occupancy Maps</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#use-cases">Use Cases</a></li>
<li class="toctree-l3"><a class="reference internal" href="#workflow-overview">Workflow Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-1-generate-semantic-occupancy-maps">Step 1: Generate Semantic Occupancy Maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-visualize-occupancy-maps">Step 2: Visualize Occupancy Maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-integration">Dataset Integration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#citation">Citation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#support-and-contact">Support and Contact</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="modalities.html">Modalities</a></li>
<li class="toctree-l1"><a class="reference internal" href="environments.html">Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="troubleshooting.html">Troubleshooting</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">TartanAir</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">TartanGround Dataset</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/tartanground.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="tartanground-dataset">
<h1>TartanGround Dataset<a class="headerlink" href="#tartanground-dataset" title="Link to this heading">ïƒ</a></h1>
<p>Welcome to the <strong>TartanGround</strong> dataset documentation â€” a large-scale dataset for ground robot perception and navigation.</p>
<img alt="TartanGround Dataset Badge" src="https://img.shields.io/badge/Dataset-TartanGround-blue" />
<a class="reference external image-reference" href="https://arxiv.org/pdf/2505.10696"><img alt="arXiv Paper Badge" src="https://img.shields.io/badge/arXiv-2505.10696-red" />
</a>
<section id="quick-links">
<h2>Quick Links<a class="headerlink" href="#quick-links" title="Link to this heading">ïƒ</a></h2>
<table class="borderless docutils align-default">
<colgroup>
<col style="width: 30.0%" />
<col style="width: 70.0%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p>ğŸŒ <strong>Dataset Webpage</strong></p></td>
<td><p><a class="reference external" href="https://tartanair.org/tartanground/">TartanGround</a></p></td>
</tr>
<tr class="row-even"><td><p>ğŸ“„ <strong>Paper</strong></p></td>
<td><p><a class="reference external" href="https://arxiv.org/pdf/2505.10696">arXiv:2505.10696</a></p></td>
</tr>
<tr class="row-odd"><td><p>ğŸ’» <strong>GitHub Repository</strong></p></td>
<td><p><a class="reference external" href="https://github.com/castacks/tartanairpy">castacks/tartanairpy</a></p></td>
</tr>
<tr class="row-even"><td><p>ğŸ“Š <strong>Metadata</strong></p></td>
<td><p><a class="reference external" href="https://docs.google.com/spreadsheets/d/1d_px4Ss19OmrJrdOLwPsVNYe7Blcdmr6JKs0GdOORCg/edit?usp=sharing">Google Sheet</a></p></td>
</tr>
</tbody>
</table>
</section>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Link to this heading">ïƒ</a></h2>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1"># 1. Create and activate conda environment</span>
<span class="linenos"> 2</span>conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>tartanground<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.9
<span class="linenos"> 3</span>conda<span class="w"> </span>activate<span class="w"> </span>tartanground
<span class="linenos"> 4</span>
<span class="linenos"> 5</span><span class="c1"># 2. Clone repository with all submodules</span>
<span class="linenos"> 6</span>git<span class="w"> </span>clone<span class="w"> </span>--recursive<span class="w"> </span>git@github.com:castacks/tartanairpy.git
<span class="linenos"> 7</span><span class="nb">cd</span><span class="w"> </span>tartanairpy
<span class="linenos"> 8</span>
<span class="linenos"> 9</span><span class="c1"># 3. Ensure submodules are up to date</span>
<span class="linenos">10</span>git<span class="w"> </span>submodule<span class="w"> </span>update<span class="w"> </span>--init<span class="w"> </span>--recursive
<span class="linenos">11</span>
<span class="linenos">12</span><span class="c1"># 4. Install the package</span>
<span class="linenos">13</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Make sure you have <code class="docutils literal notranslate"><span class="pre">git</span></code> and <code class="docutils literal notranslate"><span class="pre">conda</span></code> installed on your system before proceeding.</p>
</div>
</section>
<section id="dataset-structure">
<h2>Dataset Structure<a class="headerlink" href="#dataset-structure" title="Link to this heading">ïƒ</a></h2>
<p>The TartanGround dataset is organized hierarchically by <strong>environment</strong> and <strong>robot type</strong>. Each environment contains data for multiple robot platforms with comprehensive sensor modalities.</p>
<section id="directory-layout">
<h3>Directory Layout<a class="headerlink" href="#directory-layout" title="Link to this heading">ïƒ</a></h3>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span>TartanGround_Root/
<span class="linenos"> 2</span>â”œâ”€â”€ AbandonedCable/
<span class="linenos"> 3</span>â”‚   â”œâ”€â”€ AbandonedCable_rgb.pcd      # Global RGB point cloud
<span class="linenos"> 4</span>â”‚   â”œâ”€â”€ AbandonedCable_sem.pcd      # Global Semantic point cloud
<span class="linenos"> 5</span>â”‚   â”œâ”€â”€ seg_label_map.json          # Semantic segmentation label map
<span class="linenos"> 6</span>â”‚   â”œâ”€â”€ Data_omni/                  # Omnidirectional robot data
<span class="linenos"> 7</span>â”‚   â”‚   â”œâ”€â”€ P0000/
<span class="linenos"> 8</span>â”‚   â”‚   â”‚   â”œâ”€â”€ image_lcam_front/
<span class="linenos"> 9</span>â”‚   â”‚   â”‚   â”œâ”€â”€ depth_lcam_front/
<span class="linenos">10</span>â”‚   â”‚   â”‚   â”œâ”€â”€ seg_lcam_front/
<span class="linenos">11</span>â”‚   â”‚   â”‚   â”œâ”€â”€ imu/
<span class="linenos">12</span>â”‚   â”‚   â”‚   â”œâ”€â”€ lidar/
<span class="linenos">13</span>â”‚   â”‚   â”‚   â”œâ”€â”€ pose_lcam_front.txt
<span class="linenos">14</span>â”‚   â”‚   â”‚   â”œâ”€â”€ P0000_metadata.json
<span class="linenos">15</span>â”‚   â”‚   â”‚   â”œâ”€â”€ image_lcam_left/
<span class="linenos">16</span>â”‚   â”‚   â”‚   â””â”€â”€ ...
<span class="linenos">17</span>â”‚   â”‚   â””â”€â”€ P00XX/
<span class="linenos">18</span>â”‚   â”œâ”€â”€ Data_diff/                  # Differential drive robot data
<span class="linenos">19</span>â”‚   â”‚   â”œâ”€â”€ P1000/
<span class="linenos">20</span>â”‚   â”‚   â””â”€â”€ P10XX/
<span class="linenos">21</span>â”‚   â””â”€â”€ Data_anymal/                # Quadrupedal robot data
<span class="linenos">22</span>â”‚       â”œâ”€â”€ P2000/
<span class="linenos">23</span>â”‚       â””â”€â”€ P20XX/
<span class="linenos">24</span>â”œâ”€â”€ AbandonedFactory/
<span class="linenos">25</span>â”‚   â””â”€â”€ (same structure as above)
<span class="linenos">26</span>â””â”€â”€ ...
</pre></div>
</div>
</section>
<section id="robot-platforms">
<h3>Robot Platforms<a class="headerlink" href="#robot-platforms" title="Link to this heading">ïƒ</a></h3>
<table class="robot-table docutils align-default" id="id2">
<caption><span class="caption-text"><strong>Supported Robot Types</strong></span><a class="headerlink" href="#id2" title="Link to this table">ïƒ</a></caption>
<colgroup>
<col style="width: 15.0%" />
<col style="width: 25.0%" />
<col style="width: 25.0%" />
<col style="width: 35.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Robot</strong></p></th>
<th class="head"><p><strong>Type</strong></p></th>
<th class="head"><p><strong>Trajectory IDs</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">omni</span></code></p></td>
<td><p>Omnidirectional</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">P0000</span></code>, <code class="docutils literal notranslate"><span class="pre">P0001</span></code>, â€¦</p></td>
<td><p>Holonomic movement in all directions</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">diff</span></code></p></td>
<td><p>Differential Drive</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">P1000</span></code>, <code class="docutils literal notranslate"><span class="pre">P1001</span></code>, â€¦</p></td>
<td><p>Differential wheeled robot</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">anymal</span></code></p></td>
<td><p>Quadrupedal</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">P2000</span></code>, <code class="docutils literal notranslate"><span class="pre">P2001</span></code>, â€¦</p></td>
<td><p>Legged robot for complex terrains</p></td>
</tr>
</tbody>
</table>
</section>
<section id="camera-configuration">
<h3>Camera Configuration<a class="headerlink" href="#camera-configuration" title="Link to this heading">ïƒ</a></h3>
<p>Each robot is equipped with a stereo <strong>6-cam setup</strong> providing full 360Â° coverage (similar to Tartanair-v2: <a class="reference internal" href="modalities.html"><span class="doc">Modalities</span></a>).</p>
<table class="docutils align-default" id="id3">
<caption><span class="caption-text"><strong>Camera Specifications</strong></span><a class="headerlink" href="#id3" title="Link to this table">ïƒ</a></caption>
<colgroup>
<col style="width: 25.0%" />
<col style="width: 75.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Parameter</strong></p></th>
<th class="head"><p><strong>Value</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Camera Positions</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">front</span></code>, <code class="docutils literal notranslate"><span class="pre">left</span></code>, <code class="docutils literal notranslate"><span class="pre">right</span></code>, <code class="docutils literal notranslate"><span class="pre">back</span></code>, <code class="docutils literal notranslate"><span class="pre">top</span></code>, <code class="docutils literal notranslate"><span class="pre">bottom</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Field of View</strong></p></td>
<td><p>90Â° (each camera)</p></td>
</tr>
<tr class="row-even"><td><p><strong>Resolution</strong></p></td>
<td><p>640Ã—640 pixels</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Stereo Configuration</strong></p></td>
<td><p>Left (<code class="docutils literal notranslate"><span class="pre">lcam_*</span></code>) and Right (<code class="docutils literal notranslate"><span class="pre">rcam_*</span></code>) pairs available</p></td>
</tr>
</tbody>
</table>
<section id="available-camera-names">
<h4>Available Camera Names<a class="headerlink" href="#available-camera-names" title="Link to this heading">ïƒ</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Left cameras</span>
<span class="p">[</span><span class="s1">&#39;lcam_front&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_right&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_left&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_back&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_top&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_bottom&#39;</span><span class="p">]</span>

<span class="c1"># Right cameras</span>
<span class="p">[</span><span class="s1">&#39;rcam_front&#39;</span><span class="p">,</span> <span class="s1">&#39;rcam_right&#39;</span><span class="p">,</span> <span class="s1">&#39;rcam_left&#39;</span><span class="p">,</span> <span class="s1">&#39;rcam_back&#39;</span><span class="p">,</span> <span class="s1">&#39;rcam_top&#39;</span><span class="p">,</span> <span class="s1">&#39;rcam_bottom&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
</section>
<section id="sensor-modalities">
<h3>Sensor Modalities<a class="headerlink" href="#sensor-modalities" title="Link to this heading">ïƒ</a></h3>
<p>The dataset provides multi-modal sensor data to support various robotic perception tasks:</p>
<ul class="simple">
<li><p><strong>RGB Images</strong> (<code class="docutils literal notranslate"><span class="pre">image</span></code>): Color images for visual perception</p></li>
<li><p><strong>Depth Maps</strong> (<code class="docutils literal notranslate"><span class="pre">depth</span></code>): Accurate depth information for 3D scene understanding</p></li>
<li><p><strong>Semantic Segmentation</strong> (<code class="docutils literal notranslate"><span class="pre">seg</span></code>): Pixel-wise semantic labels</p></li>
<li><p><strong>IMU Data</strong> (<code class="docutils literal notranslate"><span class="pre">imu</span></code>): Inertial measurement unit data</p></li>
<li><p><strong>LiDAR Point Clouds</strong> (<code class="docutils literal notranslate"><span class="pre">lidar</span></code>): 3D point cloud data (32 Beam simulated LiDAR)</p></li>
<li><p><strong>Robot Poses</strong> (<code class="docutils literal notranslate"><span class="pre">meta</span></code>): Ground truth 6-DOF poses and metadata including robot height</p></li>
<li><p><strong>Global Point Clouds</strong>:</p>
<ul>
<li><p>RGB Point Clouds (<code class="docutils literal notranslate"><span class="pre">rgb_pcd</span></code>): Colored 3D representations of entire environments</p></li>
<li><p>Semantic Point Clouds (<code class="docutils literal notranslate"><span class="pre">sem_pcd</span></code>): Point clouds with semantic labels</p></li>
</ul>
</li>
<li><p><strong>Segmentation Labels</strong> (<code class="docutils literal notranslate"><span class="pre">seg_labels</span></code>): Label mappings for semantic segmentation tasks</p></li>
<li><p><strong>ROS Bags</strong> (<code class="docutils literal notranslate"><span class="pre">rosbag</span></code>): Proprioceptive data with joint states (available for <code class="docutils literal notranslate"><span class="pre">anymal</span></code> robot only)</p></li>
</ul>
<section id="available-modalities">
<h4>Available Modalities<a class="headerlink" href="#available-modalities" title="Link to this heading">ïƒ</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Complete list of available modalities</span>
<span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="s1">&#39;meta&#39;</span><span class="p">,</span> <span class="s1">&#39;depth&#39;</span><span class="p">,</span> <span class="s1">&#39;seg&#39;</span><span class="p">,</span> <span class="s1">&#39;lidar&#39;</span><span class="p">,</span> <span class="s1">&#39;imu&#39;</span><span class="p">,</span> <span class="s1">&#39;rosbag&#39;</span><span class="p">,</span> <span class="s1">&#39;sem_pcd&#39;</span><span class="p">,</span> <span class="s1">&#39;seg_labels&#39;</span><span class="p">,</span> <span class="s1">&#39;rgb_pcd&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">rosbag</span></code> modality is only available for the <code class="docutils literal notranslate"><span class="pre">anymal</span></code> (quadrupedal) robot version.</p>
</div>
</section>
</section>
</section>
<section id="download-dataset">
<h2>Download Dataset<a class="headerlink" href="#download-dataset" title="Link to this heading">ïƒ</a></h2>
<p>The TartanGround dataset can be downloaded using the <strong>tartanairpy</strong> Python toolkit. The repository includes ready-to-use examples in <code class="docutils literal notranslate"><span class="pre">examples/download_ground_example.py</span></code>.</p>
<section id="download-examples">
<h3>Download Examples<a class="headerlink" href="#download-examples" title="Link to this heading">ïƒ</a></h3>
<p><strong>Example 1 â€“ Download all modalities for specific environments and robots:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tartanair</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ta</span>

<span class="n">ta</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;/path/to/tartanground/root&#39;</span><span class="p">)</span>

<span class="n">env</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;AbandonedFactory&quot;</span><span class="p">,</span> <span class="s2">&quot;ConstructionSite&quot;</span><span class="p">,</span> <span class="s2">&quot;Hospital&quot;</span><span class="p">]</span>

<span class="n">ta</span><span class="o">.</span><span class="n">download_ground</span><span class="p">(</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="p">,</span>
    <span class="n">version</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;omni&#39;</span><span class="p">,</span> <span class="s1">&#39;diff&#39;</span><span class="p">,</span> <span class="s1">&#39;anymal&#39;</span><span class="p">],</span>
    <span class="n">traj</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">modality</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="s1">&#39;meta&#39;</span><span class="p">,</span> <span class="s1">&#39;depth&#39;</span><span class="p">,</span> <span class="s1">&#39;seg&#39;</span><span class="p">,</span> <span class="s1">&#39;lidar&#39;</span><span class="p">,</span> <span class="s1">&#39;imu&#39;</span><span class="p">,</span>
        <span class="s1">&#39;rosbag&#39;</span><span class="p">,</span> <span class="s1">&#39;sem_pcd&#39;</span><span class="p">,</span> <span class="s1">&#39;seg_labels&#39;</span><span class="p">,</span> <span class="s1">&#39;rgb_pcd&#39;</span>
    <span class="p">],</span>
    <span class="n">camera_name</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lcam_front&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_right&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_left&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_back&#39;</span><span class="p">],</span>
    <span class="n">unzip</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Example 2 â€“ Download one trajectory from each environment (Omnidirectional robot only):</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tartanair</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ta</span>

<span class="n">ta</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;/path/to/tartanground/root&#39;</span><span class="p">)</span>

<span class="n">ta</span><span class="o">.</span><span class="n">download_ground</span><span class="p">(</span>
    <span class="n">env</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">version</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;omni&#39;</span><span class="p">],</span>
    <span class="n">traj</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;P0000&#39;</span><span class="p">],</span>
    <span class="n">modality</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">camera_name</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lcam_front&#39;</span><span class="p">],</span>
    <span class="n">unzip</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Example 3 â€“ Download semantic occupancy data only:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tartanair</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ta</span>

<span class="n">ta</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;/path/to/tartanground/root&#39;</span><span class="p">)</span>

<span class="n">ta</span><span class="o">.</span><span class="n">download_ground</span><span class="p">(</span>
    <span class="n">env</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">version</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">traj</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">modality</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;seg_labels&#39;</span><span class="p">,</span> <span class="s1">&#39;sem_pcd&#39;</span><span class="p">],</span>
    <span class="n">camera_name</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">unzip</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
<p><strong>Example 4 â€“ Download entire dataset (~15 TB):</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tartanair</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ta</span>

<span class="n">ta</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;/path/to/tartanground/root&#39;</span><span class="p">)</span>

<span class="n">ta</span><span class="o">.</span><span class="n">download_ground</span><span class="p">(</span>
    <span class="n">env</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">version</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">traj</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">modality</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">camera_name</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">unzip</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="multi-threaded-download">
<h3>Multi-threaded Download<a class="headerlink" href="#multi-threaded-download" title="Link to this heading">ïƒ</a></h3>
<p>For faster downloads, use the multi-threaded version:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">tartanair</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">ta</span>

<span class="n">ta</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="s1">&#39;/path/to/tartanground/root&#39;</span><span class="p">)</span>

<span class="n">ta</span><span class="o">.</span><span class="n">download_ground_multi_thread</span><span class="p">(</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">env</span><span class="p">,</span>
    <span class="n">version</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;omni&#39;</span><span class="p">,</span> <span class="s1">&#39;diff&#39;</span><span class="p">,</span> <span class="s1">&#39;anymal&#39;</span><span class="p">],</span>
    <span class="n">traj</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">modality</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;image&#39;</span><span class="p">,</span> <span class="s1">&#39;meta&#39;</span><span class="p">,</span> <span class="s1">&#39;depth&#39;</span><span class="p">,</span> <span class="s1">&#39;seg&#39;</span><span class="p">,</span> <span class="s1">&#39;lidar&#39;</span><span class="p">,</span> <span class="s1">&#39;imu&#39;</span><span class="p">,</span>
        <span class="s1">&#39;rosbag&#39;</span><span class="p">,</span> <span class="s1">&#39;sem_pcd&#39;</span><span class="p">,</span> <span class="s1">&#39;seg_labels&#39;</span><span class="p">,</span> <span class="s1">&#39;rgb_pcd&#39;</span>
    <span class="p">],</span>
    <span class="n">camera_name</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lcam_front&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_right&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_left&#39;</span><span class="p">,</span> <span class="s1">&#39;lcam_back&#39;</span><span class="p">],</span>
    <span class="n">unzip</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">8</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="download-process-notes">
<h3>Download Process Notes<a class="headerlink" href="#download-process-notes" title="Link to this heading">ïƒ</a></h3>
<div class="tip admonition">
<p class="admonition-title">Important Download Information</p>
<ul class="simple">
<li><p><strong>Pre-download Analysis:</strong> The script lists all files and calculates total space requirements before downloading</p></li>
<li><p><strong>File Format:</strong> Data is downloaded as zip files</p></li>
<li><p><strong>Post-processing:</strong> Use <code class="docutils literal notranslate"><span class="pre">examples/unzip_ground_files.py</span></code> to extract the downloaded data</p></li>
<li><p><strong>Multi-threading:</strong> Adjust <code class="docutils literal notranslate"><span class="pre">num_workers</span></code> parameter based on your system capabilities and network bandwidth</p></li>
</ul>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><strong>Full Examples:</strong> Comprehensive download scripts are available in <code class="docutils literal notranslate"><span class="pre">examples/download_ground_example.py</span></code> in the <a class="reference external" href="https://github.com/castacks/tartanairpy">GitHub repository</a>.</p>
</div>
</section>
</section>
<section id="dataset-statistics">
<h2>Dataset Statistics<a class="headerlink" href="#dataset-statistics" title="Link to this heading">ïƒ</a></h2>
<table class="docutils align-default" id="id4">
<caption><span class="caption-text"><strong>TartanGround Dataset Overview</strong></span><a class="headerlink" href="#id4" title="Link to this table">ïƒ</a></caption>
<colgroup>
<col style="width: 40.0%" />
<col style="width: 60.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Metric</strong></p></th>
<th class="head"><p><strong>Value</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Total Environments</strong></p></td>
<td><p>63 diverse scenarios</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Total Trajectories</strong></p></td>
<td><p>878 trajectories</p></td>
</tr>
<tr class="row-even"><td><p><strong>Robot Platforms</strong></p></td>
<td><p>3 types (Omnidirectional, Differential, Quadrupedal)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Trajectory Distribution</strong></p></td>
<td><p>440 omni, 198 diff, 240 legged</p></td>
</tr>
<tr class="row-even"><td><p><strong>Total Samples</strong></p></td>
<td><p>1.44 million samples</p></td>
</tr>
<tr class="row-odd"><td><p><strong>RGB Images</strong></p></td>
<td><p>17.3 million images</p></td>
</tr>
<tr class="row-even"><td><p><strong>Dataset Size</strong></p></td>
<td><p>~16 TB</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Samples per Trajectory</strong></p></td>
<td><p>600-8,000 samples</p></td>
</tr>
<tr class="row-even"><td><p><strong>Camera Resolution</strong></p></td>
<td><p>640Ã—640 pixels</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Data Collection Frequency</strong></p></td>
<td><p>10 Hz</p></td>
</tr>
</tbody>
</table>
<section id="environment-categories">
<h3>Environment Categories<a class="headerlink" href="#environment-categories" title="Link to this heading">ïƒ</a></h3>
<table class="docutils align-default" id="id5">
<caption><span class="caption-text"><strong>Environment Types</strong></span><a class="headerlink" href="#id5" title="Link to this table">ïƒ</a></caption>
<colgroup>
<col style="width: 30.0%" />
<col style="width: 70.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><strong>Category</strong></p></th>
<th class="head"><p><strong>Description</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Indoor</strong></p></td>
<td><p>Indoor spaces with complex layouts and lighting</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Nature</strong></p></td>
<td><p>Natural environments with varied vegetation, natural terrain and seasons</p></td>
</tr>
<tr class="row-even"><td><p><strong>Rural</strong></p></td>
<td><p>Countryside settings with varied topography</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Urban</strong></p></td>
<td><p>City environments with structured layouts</p></td>
</tr>
<tr class="row-even"><td><p><strong>Industrial/Infrastructure</strong></p></td>
<td><p>Construction sites and industrial facilities</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Historical/Thematic</strong></p></td>
<td><p>Heritage sites and specialized environments</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="semantic-occupancy-maps">
<h2>Semantic Occupancy Maps<a class="headerlink" href="#semantic-occupancy-maps" title="Link to this heading">ïƒ</a></h2>
<p>The TartanGround dataset supports <strong>semantic occupancy prediction</strong> research by providing tools to generate local 3D occupancy maps with semantic class labels. These maps are essential for training and evaluating neural networks that predict semantic occupancy from sensor observations.</p>
<section id="use-cases">
<h3>Use Cases<a class="headerlink" href="#use-cases" title="Link to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p><strong>Semantic Occupancy Prediction</strong>: Train networks to predict 3D semantic structure from 2D observations</p></li>
<li><p><strong>3D Scene Understanding</strong>: Evaluate spatial reasoning capabilities of perception models</p></li>
<li><p><strong>Navigation Planning</strong>: Generate semantically-aware path planning datasets</p></li>
<li><p><strong>Multi-modal Fusion</strong>: Combine RGB, depth, and LiDAR data for 3D semantic mapping</p></li>
</ul>
</section>
<section id="workflow-overview">
<h3>Workflow Overview<a class="headerlink" href="#workflow-overview" title="Link to this heading">ïƒ</a></h3>
<p>The semantic occupancy map generation follows a two-step process:</p>
<p><strong>Step 1: Generation</strong> - Extract local occupancy maps around each robot pose</p>
<p><strong>Step 2: Visualization</strong> - Inspect and validate the generated occupancy maps</p>
</section>
<section id="step-1-generate-semantic-occupancy-maps">
<h3>Step 1: Generate Semantic Occupancy Maps<a class="headerlink" href="#step-1-generate-semantic-occupancy-maps" title="Link to this heading">ïƒ</a></h3>
<p>Use the GPU-accelerated script to extract local semantic occupancy maps from global point clouds:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate occupancy maps for a specific trajectory</span>
python<span class="w"> </span>examples/subsample_semantic_pcd_gpu.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--root_dir<span class="w"> </span>/path/to/tartanground/dataset<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--env<span class="w"> </span>ConstructionSite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traj<span class="w"> </span>P0000
</pre></div>
</div>
<p><strong>Key Parameters:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Customize occupancy map properties</span>
python<span class="w"> </span>examples/subsample_semantic_pcd_gpu.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--root_dir<span class="w"> </span>/path/to/dataset<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--env<span class="w"> </span>ConstructionSite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traj<span class="w"> </span>P0000<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--resolution<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span><span class="se">\ </span><span class="w">                   </span><span class="c1"># Voxel size in meters</span>
<span class="w">    </span>--x_bounds<span class="w"> </span>-20<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="se">\ </span><span class="w">                  </span><span class="c1"># Local X bounds [min, max]</span>
<span class="w">    </span>--y_bounds<span class="w"> </span>-20<span class="w"> </span><span class="m">20</span><span class="w"> </span><span class="se">\ </span><span class="w">                  </span><span class="c1"># Local Y bounds [min, max]</span>
<span class="w">    </span>--z_bounds<span class="w"> </span>-3<span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="se">\ </span><span class="w">                    </span><span class="c1"># Local Z bounds [min, max]</span>
<span class="w">    </span>--subsample_poses<span class="w"> </span><span class="m">10</span><span class="w">                  </span><span class="c1"># Process every 10th pose</span>
</pre></div>
</div>
<p><strong>Output:</strong></p>
<p>The script generates <code class="docutils literal notranslate"><span class="pre">.npz</span></code> files in <code class="docutils literal notranslate"><span class="pre">{trajectory}/sem_occ/</span></code> containing:</p>
<ul class="simple">
<li><p><strong>occupancy_map</strong>: 3D voxel grid with semantic class IDs</p></li>
<li><p><strong>pose</strong>: Robot pose [x, y, z, qx, qy, qz, qw]</p></li>
<li><p><strong>bounds</strong>: Local coordinate bounds</p></li>
<li><p><strong>resolution</strong>: Voxel resolution in meters</p></li>
<li><p><strong>class_mapping</strong>: Semantic class ID to RGB color mapping</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">GPU Requirements</p>
<p>This script requires:</p>
<ul class="simple">
<li><p><strong>NVIDIA GPU</strong> with CUDA support</p></li>
<li><p><strong>CuPy library</strong> for GPU acceleration</p></li>
<li><p><strong>Sufficient GPU memory</strong> (8GB+ recommended for large environments)</p></li>
</ul>
</div>
</section>
<section id="step-2-visualize-occupancy-maps">
<h3>Step 2: Visualize Occupancy Maps<a class="headerlink" href="#step-2-visualize-occupancy-maps" title="Link to this heading">ïƒ</a></h3>
<p>Use the interactive viewer to inspect generated occupancy maps and verify their quality:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Visualize occupancy maps with navigation controls</span>
python<span class="w"> </span>examples/visualize_semantic_occ_local.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--root_dir<span class="w"> </span>/path/to/tartanground/dataset<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--env<span class="w"> </span>ConstructionSite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traj<span class="w"> </span>P0000<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--skip_samples<span class="w"> </span><span class="m">100</span>
</pre></div>
</div>
<p><strong>Customization Options:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># Customize visualization appearance</span>
python<span class="w"> </span>examples/visualize_semantic_occ_local.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--root_dir<span class="w"> </span>/path/to/dataset<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--env<span class="w"> </span>ConstructionSite<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--traj<span class="w"> </span>P0000<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--skip_samples<span class="w"> </span><span class="m">50</span><span class="w"> </span><span class="se">\ </span><span class="w">                  </span><span class="c1"># Show every 50th occupancy map</span>
<span class="w">    </span>--point_size<span class="w"> </span><span class="m">12</span>.0<span class="w"> </span><span class="se">\ </span><span class="w">                  </span><span class="c1"># Larger point visualization</span>
<span class="w">    </span>--background<span class="w"> </span>white<span class="w">                    </span><span class="c1"># White background</span>
</pre></div>
</div>
</section>
<section id="dataset-integration">
<h3>Dataset Integration<a class="headerlink" href="#dataset-integration" title="Link to this heading">ïƒ</a></h3>
<p><strong>File Structure:</strong></p>
<p>After running the generation script, your dataset structure will include:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>TartanGround_Root/
â”œâ”€â”€ ConstructionSite/
â”‚   â”œâ”€â”€ ConstructionSite_sem.pcd          # Global semantic point cloud (input)
â”‚   â”œâ”€â”€ Data_omni/
â”‚   â”‚   â”œâ”€â”€ P0000/
â”‚   â”‚   â”‚   â”œâ”€â”€ pose_lcam_front.txt       # Robot poses (input)
â”‚   â”‚   â”‚   â”œâ”€â”€ sem_occ/                  # Generated occupancy maps
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_occupancy_000000.npz
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ semantic_occupancy_000001.npz
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ (other sensor data)
â”‚   â”‚   â””â”€â”€ P0001/
â”‚   â””â”€â”€ seg_label_map.json                # Semantic class names
</pre></div>
</div>
<p><strong>Loading Occupancy Maps in Python:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Load a single occupancy map</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;semantic_occupancy_000000.npz&#39;</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">occupancy_map</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;occupancy_map&#39;</span><span class="p">]</span>     <span class="c1"># 3D array with class IDs</span>
<span class="n">pose</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;pose&#39;</span><span class="p">]</span>                       <span class="c1"># Robot pose [x,y,z,qx,qy,qz,qw]</span>
<span class="n">bounds</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;bounds&#39;</span><span class="p">]</span>                   <span class="c1"># Local bounds [x_min,x_max,y_min,y_max,z_min,z_max]</span>
<span class="n">resolution</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;resolution&#39;</span><span class="p">]</span>           <span class="c1"># Voxel size in meters</span>
<span class="n">class_mapping</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;class_mapping&#39;</span><span class="p">]</span>     <span class="c1"># Class ID to RGB mapping</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Occupancy map shape: </span><span class="si">{</span><span class="n">occupancy_map</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Resolution: </span><span class="si">{</span><span class="n">resolution</span><span class="si">}</span><span class="s2">m per voxel&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Occupied voxels: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">occupancy_map</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><strong>Complete Examples:</strong> Full parameter documentation and advanced usage examples are available in the <a class="reference external" href="https://github.com/castacks/tartanairpy/tree/main/examples">GitHub repository examples folder</a>.</p>
</div>
</section>
</section>
<section id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Link to this heading">ïƒ</a></h2>
<p>If you use the TartanGround dataset in your research, please cite:</p>
<div class="highlight-bibtex notranslate"><div class="highlight"><pre><span></span><span class="nc">@article</span><span class="p">{</span><span class="nl">patel2025tartanground</span><span class="p">,</span>
<span class="w">  </span><span class="na">title</span><span class="p">=</span><span class="s">{TartanGround: A Large-Scale Dataset for Ground Robot Perception and Navigation}</span><span class="p">,</span>
<span class="w">  </span><span class="na">author</span><span class="p">=</span><span class="s">{Patel, Manthan and Yang, Fan and Qiu, Yuheng and Cadena, Cesar and Scherer, Sebastian and Hutter, Marco and Wang, Wenshan}</span><span class="p">,</span>
<span class="w">  </span><span class="na">journal</span><span class="p">=</span><span class="s">{arXiv preprint arXiv:2505.10696}</span><span class="p">,</span>
<span class="w">  </span><span class="na">year</span><span class="p">=</span><span class="s">{2025}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="support-and-contact">
<h2>Support and Contact<a class="headerlink" href="#support-and-contact" title="Link to this heading">ïƒ</a></h2>
<p>For technical issues, questions, or bug reports, please open an issue on the <a class="reference external" href="https://github.com/castacks/tartanairpy/issues">GitHub repository</a>.</p>
<p>For applications and interesting dataset uses, visit the <a class="reference external" href="https://tartanair.org/tartanground/">dataset webpage</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="flow_sampling.html" class="btn btn-neutral float-left" title="Dense Correspondence / Flow Sampling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="usage.html" class="btn btn-neutral float-right" title="API Reference" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Carnegie Mellon University, 2023, Wenshan Wang, Yaoyu Hu, Yuheng Qiu, Shihao Shen, Yorai Shaoul..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>